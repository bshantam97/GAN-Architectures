{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim \n",
    "import torch.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Sequential):\n",
    "    \n",
    "    def __init__(self, channels_img, features_d):\n",
    "        # Did not use BatchNorm in the last layer of the generator and the first layer of the \n",
    "        # discriminator\n",
    "        # Input: N x channels_img x 64 x 64\n",
    "        modules = [nn.Conv2d(channels_img, features_d, kernel_size = 4, stride = 2, padding = 1), #32x32\n",
    "                   nn.LeakyReLU(0.2, inplace=True),\n",
    "                   self._block(features_d, features_d*2, 4, 2, 1),# 16x16\n",
    "                   self._block(features_d*2, features_d*4, 4, 2, 1), #8x8\n",
    "                   self._block(features_d*4, features_d*8, 4, 2, 1), #4x4\n",
    "                   nn.Conv2d(features_d*8, 1, kernel_size = 4, stride = 2, padding = 0), #1x1(Prediction)\n",
    "                   nn.Sigmoid()]\n",
    "        super(Discriminator, self).__init__(*modules)\n",
    "        \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels,kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "              \n",
    "class Generator(nn.Sequential):\n",
    "    \n",
    "    # Here channels_img is nothing but the inputs channels \n",
    "    # and features_g is nothing but the output channels\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        \n",
    "        modules = [self._block(z_dim, features_g*16, 4, 1, 0),\n",
    "                   self._block(features_g*16, features_g*8, 4, 2, 1),\n",
    "                   self._block(features_g*8, features_g*4, 4, 2, 1),\n",
    "                   self._block(features_g*4, features_g*2, 4, 2, 1),\n",
    "                   nn.ConvTranspose2d(features_g*2, channels_img, 4, 2, 1),\n",
    "                   nn.Tanh()]\n",
    "        super(Generator, self).__init__(*modules)\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "            \n",
    "# def test():\n",
    "#     N, in_channels, H, W = 8, 3, 64, 64\n",
    "#     z_dim = 100\n",
    "#     X = torch.randn((N, in_channels, H, W))\n",
    "#     disc = Discriminator(in_channels,8)\n",
    "#     disc.apply(weights_init)\n",
    "#     assert disc(X).shape == (N, 1, 1, 1) # One Value per example\n",
    "#     gen = Generator(z_dim, in_channels, 64)\n",
    "#     gen.apply(weights_init)\n",
    "#     z = torch.randn((N, z_dim, 1, 1))\n",
    "#     assert gen(z).shape == (N, in_channels, H, W) # Ouput Generated image\n",
    "#     print(\"Success\")\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The training Setup\n",
    "root = \"C:\\\\Users\\\\shant\\\\celeba\"\n",
    "LEARNING_RATE = 0.0002\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "# Image Channels in the generator output and input to the discriminator \n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Latent Space Dimensions\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "# feature size in the discriminator\n",
    "FEATURES_DISC = 64\n",
    "\n",
    "# feature size in the generator\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "# Setup Transforms\n",
    "dataset = datasets.ImageFolder(root=root, transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers = 2)\n",
    "\n",
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator(Z_DIM, IMAGE_CHANNELS, FEATURES_GEN).to(device)\n",
    "discriminator = Discriminator(IMAGE_CHANNELS,FEATURES_DISC).to(device)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr = LEARNING_RATE, betas = (0.5,0.999))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr = LEARNING_RATE, betas = (0.5,0.999))\n",
    "\n",
    "# Loss \n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Batch of Latent Vectors\n",
    "fixed_noise = torch.randn((64, Z_DIM, 1, 1)).to(device)\n",
    "\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "loss_curves = SummaryWriter(f\"logs/loss_curves\")\n",
    "\n",
    "step = 0 # Printing to tensorboard\n",
    "# generator.train()\n",
    "# discriminator.train()\n",
    "\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    # Unsupervised\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        discriminator.zero_grad()\n",
    "        # Latent noise\n",
    "        noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(device)\n",
    "        # The real world images\n",
    "        real = real.to(device)\n",
    "        # Pass the latent vector through the generator\n",
    "        fake = generator(noise)\n",
    "        #####################################################\n",
    "        # Train the discriminator max log(D(x)) + log(1-D(G(z)))\n",
    "        #####################################################\n",
    "        \n",
    "        disc_real = discriminator(real).view(-1)\n",
    "        # log(D(x)), y_n = ones hence only logx_n term is left. Refer to Pytorch Documentation\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        \n",
    "        loss_disc_real.backward()\n",
    "        \n",
    "        disc_fake = discriminator(fake.detach()).view(-1)\n",
    "        # Subtracting \n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        # Addition of gradients from the all the real and fake samples (D(G(z)))\n",
    "        loss_disc = (loss_disc_fake + loss_disc_real)\n",
    "        \n",
    "        loss_disc_fake.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        \n",
    "        ##################################\n",
    "        # Train Generator max log(D(G(z)))\n",
    "        ##################################\n",
    "        generator.zero_grad()\n",
    "        output = discriminator(fake).view(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        loss_gen.backward()\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "        #generator_losses.append(loss_gen.item())\n",
    "        discriminator_losses.append(loss_disc)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            \n",
    "            print(\n",
    "            f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise)\n",
    "            \n",
    "                # The [:64] prints out the 4-D tensor BxCxHxW\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    real[:64], normalize = True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:64], normalize = True)\n",
    "                ##########################\n",
    "                # TensorBoard Visualizations\n",
    "                ##########################\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "                loss_curves.add_scalar(\"generator\", loss_gen, global_step=step)\n",
    "                loss_curves.add_scalar(\"discriminator\", loss_disc, global_step = step)\n",
    "                \n",
    "            step += 1 # See progression of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
