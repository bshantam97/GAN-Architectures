{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim \n",
    "import torch.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Did not use BatchNorm in the last layer of the generator and the first layer of the \n",
    "        # discriminator\n",
    "        # Input: N x channels_img x 64 x 64\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size = 4, stride = 2, padding = 1), #32x32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d*2, 4, 2, 1),# 16x16\n",
    "            self._block(features_d*2, features_d*4, 4, 2, 1), #8x8\n",
    "            self._block(features_d*4, features_d*8, 4, 2, 1), #4x4\n",
    "            nn.Conv2d(features_d*8, 1, kernel_size = 4, stride = 2, padding = 0), #1x1(Prediction)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels,kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.discriminator(x)\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        # Is an iterator over all the modules\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,(nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "                \n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    # Here channels_img is nothing but the inputs channels \n",
    "    # and features_g is nothing but the output channels\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x z_dim x 1 x 1\n",
    "            self._block(z_dim, features_g*16, 4, 1, 0), # N x f_g*16(1024=64*64) x 4 x 4\n",
    "            self._block(features_g*16, features_g*8, 4, 2, 1), # f_g*16 x f_g*8 x 8 x 8\n",
    "            self._block(features_g*8, features_g*4, 4, 2, 1), # f_g*8 x f_g*4 x 16 x 16\n",
    "            self._block(features_g*4, features_g*2, 4, 2, 1), #32 x 32\n",
    "            nn.ConvTranspose2d(features_g*2, channels_img, 4, 2, 1),\n",
    "            nn.Tanh() #[-1,1]\n",
    "        )\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def _init_weight(self):    \n",
    "        for m in self.modules():\n",
    "            if isinstance(m,(nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            \n",
    "# def test():\n",
    "#     N, in_channels, H, W = 8, 3, 64, 64\n",
    "#     z_dim = 100\n",
    "#     X = torch.randn((N, in_channels, H, W))\n",
    "#     disc = Discriminator(in_channels,8)\n",
    "#     assert disc(X).shape == (N, 1, 1, 1) # One Value per example\n",
    "#     gen = Generator(z_dim, in_channels, 64)\n",
    "#     z = torch.randn((N, z_dim, 1, 1))\n",
    "#     assert gen(z).shape == (N, in_channels, H, W) # Ouput Generated image\n",
    "#     print(\"Success\")\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "## The training Setup\n",
    "\n",
    "device = torch.device(\"torch\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
