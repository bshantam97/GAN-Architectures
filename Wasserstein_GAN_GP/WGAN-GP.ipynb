{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"C:\\\\Users\\\\shant\\\\celeba\"\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE = 64\n",
    "Z_DIM = 100\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "IMAGE_CHANNELS = 3\n",
    "NUM_EPOCHS = 5\n",
    "IMAGE_SIZE = 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "dataset = datasets.ImageFolder(root = root , transform=transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the Wasserstein GAN\n",
    "# WGAN Has better stability and loss means something for WGAN: Its a termination criteria\n",
    "# WGAN Also prevents Mode Collapse(Model only outputs specific classes)\n",
    "# When Discriminator converged to 0 obtained great results\n",
    "\n",
    "class Generator(nn.Sequential):\n",
    "    \"\"\"\n",
    "    z_dim: \n",
    "    channels_img: Input channels(for example for an RGB image this value is 3)\n",
    "    features_g: Size of the output feature map(In this case its 64x64)\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        \n",
    "        modules = [self._block(z_dim, features_g*16, 4, 1, 0),\n",
    "                   self._block(features_g*16, features_g*8, 4, 2, 1),\n",
    "                   self._block(features_g*8, features_g*4, 4, 2, 1),\n",
    "                   self._block(features_g*4, features_g*2, 4, 2, 1),\n",
    "                   nn.ConvTranspose2d(features_g*2, channels_img, 4, 2, 1),\n",
    "                   nn.Tanh()]\n",
    "        \n",
    "        super(Generator, self).__init__(*modules)\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "class Critic(nn.Sequential):\n",
    "    \n",
    "    def __init__(self, channels_img, features_d):\n",
    "        \n",
    "        modules = [nn.Conv2d(channels_img, features_d, kernel_size = 4, stride = 2, padding = 1), #32x32\n",
    "                   nn.LeakyReLU(0.2, inplace=True),\n",
    "                   self._block(features_d, features_d*2, 4, 2, 1),# 16x16\n",
    "                   self._block(features_d*2, features_d*4, 4, 2, 1), #8x8\n",
    "                   self._block(features_d*4, features_d*8, 4, 2, 1), #4x4\n",
    "                   nn.Conv2d(features_d*8, 1, kernel_size = 4, stride = 2, padding = 0)]\n",
    "        \n",
    "        super(Critic, self).__init__(*modules)\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "         nn.Conv2d(in_channels, out_channels,kernel_size, stride, padding, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels, affine = True), # Learnable Parameters\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def gradient_penalty(critic, real, fake, device = \"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    # Creating interpolated images\n",
    "    epsilon = torch.randn([BATCH_SIZE, 1, 1, 1]).repeat(1,1,1,1).to(device)\n",
    "    interpolated_images = real*epsilon + fake * (1-epsilon)\n",
    "\n",
    "    #calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Compute the gradients with respect to the interpolated images, just need the first value\n",
    "    gradient = torch.autograd.grad(inputs = interpolated_images, \n",
    "    outputs = mixed_scores, \n",
    "    grad_outputs = torch.ones_like(mixed_scores),\n",
    "    create_graph=True,\n",
    "    retain_graph=True)[0]\n",
    "\n",
    "    # Number of Dimension\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim = 1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1)**2)\n",
    "\n",
    "    return gradient_penalty\n",
    "\n",
    "# def test():\n",
    "#     N, in_channels, H, W = 8, 3, 64, 64\n",
    "#     z_dim = 100\n",
    "#     X = torch.randn((N, in_channels, H, W))\n",
    "#     disc = Critic(in_channels,8)\n",
    "#     disc.apply(weights_init)\n",
    "#     assert disc(X).shape == (N, 1, 1, 1) # One Value per example\n",
    "#     gen = Generator(z_dim, in_channels, 64)\n",
    "#     gen.apply(weights_init)\n",
    "#     z = torch.randn((N, z_dim, 1, 1))\n",
    "#     assert gen(z).shape == (N, in_channels, H, W) # Ouput Generated image\n",
    "#     print(\"Success\")\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Generator and Discriminator Model objects\n",
    "########################\n",
    "generator = Generator(Z_DIM,IMAGE_CHANNELS,FEATURES_GEN).to(device)\n",
    "critic = Critic(IMAGE_CHANNELS,FEATURES_DISC).to(device)\n",
    "\n",
    "########################\n",
    "# Weight Initialization for the model\n",
    "########################\n",
    "generator.apply(weights_init)\n",
    "critic.apply(weights_init)\n",
    "\n",
    "########################\n",
    "# Optimizers for Critic and the Generator\n",
    "########################\n",
    "optimizer_gen = optim.Adam(generator.parameters(), lr = LEARNING_RATE, betas = (0,0.9))\n",
    "optimizer_critic = optim.Adam(critic.parameters(), lr = LEARNING_RATE, betas = (0,0.9))\n",
    "\n",
    "#######################\n",
    "# Create tensorboard SummaryWriter objects to display generated fake images and associated loss curves\n",
    "#######################\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "loss_curves = SummaryWriter(f\"logs/loss_curves\")\n",
    "\n",
    "#######################\n",
    "# Create a batch of latent vectors. Will be used to to do a single pass through the generator after \n",
    "# the training has terminated\n",
    "#######################\n",
    "fixed_noise = torch.randn((64, Z_DIM, 1, 1)).to(device)\n",
    "\n",
    "step = 0 # For printing to tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 0/3166                   Loss D: 189.9386, loss G: 0.8411\n",
      "Epoch [0/5] Batch 100/3166                   Loss D: -75.9391, loss G: 53.4252\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    # Unsupervised\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        \n",
    "        # The real world images\n",
    "        real = real.to(device)\n",
    "        \n",
    "        #####################################################\n",
    "        # Train the Critic\n",
    "        #####################################################\n",
    "        \n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            critic.zero_grad()\n",
    "            # Latent noise\n",
    "            noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(device)\n",
    "            # Pass the latent vector through the generator\n",
    "            fake = generator(noise)     \n",
    "            critic_real = critic(real).view(-1)\n",
    "            critic_fake = critic(fake.detach()).view(-1)\n",
    "            gp = gradient_penalty(critic, real, fake, device=device)\n",
    "            ## Loss for the critic. Taking -ve because RMSProp are designed to minimize \n",
    "            ## Hence to minimize something -ve is equivalent to maximizing that expression\n",
    "            loss_critic = (-(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP*gp) \n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            optimizer_critic.step()\n",
    "\n",
    "        #############################\n",
    "        # Train the generator minimizing -E[critic(gen_fake)]\n",
    "        #############################\n",
    "        generator.zero_grad()\n",
    "        output = critic(fake).view(-1)\n",
    "        loss_gen = -torch.mean(output)\n",
    "        loss_gen.backward()\n",
    "        optimizer_gen.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            \n",
    "            print(\n",
    "            f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise)\n",
    "            \n",
    "                # The [:64] prints out the 4-D tensor BxCxHxW\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    real[:64], normalize = True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:64], normalize = True)\n",
    "                ##########################\n",
    "                # TensorBoard Visualizations\n",
    "                ##########################\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "#                 loss_curves.add_scalar(\"generator\", {loss_gen, global_step=step)\n",
    "                loss_curves.add_scalars(\"curves\", {\n",
    "                    \"generator\":loss_gen, \"critic\":loss_critic\n",
    "                }, global_step = step)\n",
    "#                 loss_curves.add_scalar(\"discriminator\", loss_disc, global_step = step)\n",
    "                \n",
    "            step += 1 # See progression of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
