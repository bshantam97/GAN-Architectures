{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import \n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"C:\\\\Users\\\\shant\\\\celeba\"\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE = 64\n",
    "Z_DIM = 100\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "IMAGE_CHANNELS = 3\n",
    "NUM_EPOCHS = 5\n",
    "IMAGE_SIZE = 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "dataset = datasets.ImageFolder(root = root , transform=transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the Wasserstein GAN\n",
    "# WGAN Has better stability and loss means something for WGAN: Its a termination criteria\n",
    "# WGAN Also prevents Mode Collapse(Model only outputs specific classes)\n",
    "# When Discriminator converged to 0 obtained great results\n",
    "\n",
    "class Generator(nn.Sequential):\n",
    "    \"\"\"\n",
    "    z_dim: \n",
    "    channels_img: Input channels(for example for an RGB image this value is 3)\n",
    "    features_g: Size of the output feature map(In this case its 64x64)\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        \n",
    "        modules = [self._block(z_dim, features_g*16, 4, 1, 0),\n",
    "                   self._block(features_g*16, features_g*8, 4, 2, 1),\n",
    "                   self._block(features_g*8, features_g*4, 4, 2, 1),\n",
    "                   self._block(features_g*4, features_g*2, 4, 2, 1),\n",
    "                   nn.ConvTranspose2d(features_g*2, channels_img, 4, 2, 1),\n",
    "                   nn.Tanh()]\n",
    "        \n",
    "        super(Generator, self).__init__(*modules)\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "class Critic(nn.Sequential):\n",
    "    \n",
    "    def __init__(self, channels_img, features_d):\n",
    "        \n",
    "        modules = [nn.Conv2d(channels_img, features_d, kernel_size = 4, stride = 2, padding = 1), #32x32\n",
    "                   nn.LeakyReLU(0.2, inplace=True),\n",
    "                   self._block(features_d, features_d*2, 4, 2, 1),# 16x16\n",
    "                   self._block(features_d*2, features_d*4, 4, 2, 1), #8x8\n",
    "                   self._block(features_d*4, features_d*8, 4, 2, 1), #4x4\n",
    "                   nn.Conv2d(features_d*8, 1, kernel_size = 4, stride = 2, padding = 0)]\n",
    "        \n",
    "        super(Critic, self).__init__(*modules)\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "         nn.Conv2d(in_channels, out_channels,kernel_size, stride, padding, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels, affine = True), # Learnable Parameters\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def gradient_penalty(critic, real, fake, device = \"cpu\"):\n",
    "    batch_size, C, H, W = real.shape\n",
    "    # Creating interpolated images\n",
    "    epsilon = torch.randn([batch_size, 1, 1, 1]).repeat(1,C,H,W).to(device)\n",
    "    interpolated_images = epsilon*real + (1-epsilon) * fake\n",
    "\n",
    "    #calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Compute the gradients with respect to the interpolated images, just need the first value\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs = interpolated_images, \n",
    "        outputs = mixed_scores, \n",
    "        grad_outputs = torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]\n",
    "\n",
    "    # Number of Dimension\n",
    "    # Calculate the Norm of the gradient to Eforce 1-Lipschitz Constraint\n",
    "    gradient = gradient.view(gradient.size(0), -1)\n",
    "    gradient_norm = gradient.norm(2, dim = 1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1)**2)\n",
    "\n",
    "    return gradient_penalty\n",
    "\n",
    "# def test():\n",
    "#     N, in_channels, H, W = 8, 3, 64, 64\n",
    "#     z_dim = 100\n",
    "#     X = torch.randn((N, in_channels, H, W))\n",
    "#     disc = Critic(in_channels,8)\n",
    "#     disc.apply(weights_init)\n",
    "#     assert disc(X).shape == (N, 1, 1, 1) # One Value per example\n",
    "#     gen = Generator(z_dim, in_channels, 64)\n",
    "#     gen.apply(weights_init)\n",
    "#     z = torch.randn((N, z_dim, 1, 1))\n",
    "#     assert gen(z).shape == (N, in_channels, H, W) # Ouput Generated image\n",
    "#     print(\"Success\")\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SummaryWriter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8b35447f47b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Create tensorboard SummaryWriter objects to display generated fake images and associated loss curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#######################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mwriter_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"logs/real\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mwriter_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"logs/fake\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mloss_curves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"logs/loss_curves\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SummaryWriter' is not defined"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Generator and Discriminator Model objects\n",
    "########################\n",
    "generator = Generator(Z_DIM,IMAGE_CHANNELS,FEATURES_GEN).to(device)\n",
    "critic = Critic(IMAGE_CHANNELS,FEATURES_DISC).to(device)\n",
    "\n",
    "########################\n",
    "# Weight Initialization for the model\n",
    "########################\n",
    "generator.apply(weights_init)\n",
    "critic.apply(weights_init)\n",
    "\n",
    "########################\n",
    "# Optimizers for Critic and the Generator\n",
    "########################\n",
    "optimizer_gen = optim.Adam(generator.parameters(), lr = LEARNING_RATE, betas = (0,0.9))\n",
    "optimizer_critic = optim.Adam(critic.parameters(), lr = LEARNING_RATE, betas = (0,0.9))\n",
    "\n",
    "#######################\n",
    "# Create tensorboard SummaryWriter objects to display generated fake images and associated loss curves\n",
    "#######################\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "loss_curves = SummaryWriter(f\"logs/loss_curves\")\n",
    "\n",
    "#######################\n",
    "# Create a batch of latent vectors. Will be used to to do a single pass through the generator after \n",
    "# the training has terminated\n",
    "#######################\n",
    "fixed_noise = torch.randn((64, Z_DIM, 1, 1)).to(device)\n",
    "\n",
    "step = 0 # For printing to tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
